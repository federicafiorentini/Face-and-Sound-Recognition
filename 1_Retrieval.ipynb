{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mtcnn\n",
    "import keras\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import mobilenet_v2\n",
    "from tqdm import tqdm\n",
    "keras.__version__\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "import joblib\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import os\n",
    "import mtcnn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and face detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name=os.listdir('thumbnails_features_deduped_publish')\n",
    "maximages=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "def load_data():\n",
    "    base_path = 'thumbnails_features_deduped_publish/'\n",
    "    paths = []\n",
    "    faces = []\n",
    "  \n",
    "    for vip in tqdm(list_name):\n",
    "        base_path_name = base_path + vip\n",
    "        results=[]\n",
    "    \n",
    "        for fi,f in enumerate(sorted(os.listdir(base_path_name))):\n",
    "            if f.endswith('.jpg') and fi<maximages and results == []:\n",
    "            \n",
    "                cur_path = base_path_name + '/' + f\n",
    "          \n",
    "                image = kimage.load_img(cur_path, target_size=(224, 224))\n",
    "                foto = image.convert('RGB')\n",
    "                # convert to array\n",
    "                pixels = np.asarray(foto)\n",
    "                # create the detector, using default weights\n",
    "                detector = mtcnn.MTCNN()\n",
    "                # detect faces in the image\n",
    "                results = detector.detect_faces(pixels)\n",
    "                \n",
    "                if results != [] :\n",
    "                    # extract the bounding box from the first face\n",
    "                    x1, y1, width, height = results[0]['box']\n",
    "                    # bug fix\n",
    "                    x1, y1 = abs(x1), abs(y1)\n",
    "                    x2, y2 = x1 + width, y1 + height\n",
    "                    # extract the face\n",
    "                    face = pixels[y1:y2, x1:x2]\n",
    "                    # resize pixels to the model size\n",
    "                    faccia = Image.fromarray(face)\n",
    "                    faccia = faccia.resize(size=(224,224))\n",
    "                    face_array = np.asarray(faccia)\n",
    "                    faces.append(face_array)\n",
    "\n",
    "                    paths.append(cur_path)\n",
    "                elif fi>maximages and results==[] :\n",
    "                    print ('skipped' + vip)\n",
    "\n",
    "    return faces, paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facce, paths = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(facce,paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero di immagini analizzate\n",
    "print (len(paths), len(facce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction with MobileNet pre-trained on imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', pooling='max', input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_features(img):\n",
    "    x = kimage.img_to_array(img)\n",
    "    x = mobilenet_v2.preprocess_input(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    f = net.predict(x)\n",
    "    return f.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor():\n",
    "    features=[]\n",
    "    for face in tqdm(facce):\n",
    "        cur_features = neural_features(face)\n",
    "        features.append(cur_features)\n",
    "  \n",
    "    features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensioni matrice di features estratte\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KDTree building and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = KDTree(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio albero di ricerca\n",
    "joblib.dump(tree, 'RetrievalTree.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio paths immagini\n",
    "joblib.dump(paths,'Paths.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml] *",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
